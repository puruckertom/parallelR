---
title: "parallelR"
output: html_document
---

* [cran task view](https://cran.r-project.org/web/views/HighPerformanceComputing.html)
* [presentation](https://docs.google.com/presentation/d/1gPVlG1pzpnMfsWTLmNXCk8HD5FmP9DuxZhsoazl2S7Q)
* [git repo](https://github.com/puruckertom/parallelR)
* [parallel library](https://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf)

```{r, echo = TRUE}
amdahl_calc <- function(p, Ncpus, singlecoreT){
  vec <- vector(mode="double", length = Ncpus)
  for(i in 1:Ncpus){vec[i] = singlecoreT * (p + (1-p)/i)}
  return(vec)
}
amdahl_calc(.01,64,100)
```

Create figure for Amdahls calculations bersus number of CPUs.
```{r, echo = TRUE}
Ncpus = 64
cpus <- 1:Ncpus
mat_cpus <- rbind(cpus, cpus, cpus, cpus)
amdahl <- matrix(data = NA, nrow = 4, ncol = Ncpus)
singlecoreT <- 100
serialP <- c(0.01,0.2,0.5,0.9)
for(i in 1:length(serialP)){amdahl[i,cpus]<- amdahl_calc(serialP[i],Ncpus,singlecoreT)}
plot(mat_cpus, amdahl, col=c("red","blue", "green", "black"), main="Amdahls' Law", sub="serialP + (1-serialP)/cpus", ylim=c(0,100))
```

Profiling, install lineprof.
```{r, echo = TRUE}
install.packages("devtools")
library(devtools)
devtools::install_github("hadley/lineprof")
library(lineprof)
f <- function() {
  pause(0.1)
  g()
  h()
}
g <- function() {
  pause(0.1)
  h()
}
h <- function() {
  pause(0.1)
}
```

The parallel package ships with R and does not need to be installed. parallel integrates the older (but still maintained) snow and multicore libraries. 
```{r, echo = TRUE}
library(parallel)
```

The parallel method detectCores will try to estimate the number of cores available (logical or physical). OS-dependent. Almost all physical CPUs will have 2 or more cores.

```{r, echo = TRUE}
Ncoreslogical <- detectCores(logical = TRUE)
Ncoreslogical
Ncores <- detectCores(logical = FALSE)
Ncores
```

The number of physical cores is generally the number of worker processes you want to create. The simplest approach is to split your task into chunks equal to the number of workers that are roughly the same size.

We implement callable function that will sleep for a given amount of time.
```{r, echo = TRUE}
chill <- function(i){
  function(x) Sys.sleep(i)
}
```

Then call it in a serial/non-parallel manner with lapply.
```{r, echo = TRUE}
#serial
system.time(lapply(1:10, chill(2)))
```

The parallel package methods mclapply (mac/linux) and parLapply (windows) are straight-up replacements for apply functions.
```{r, echo = TRUE}
#parallel
if(Sys.info()['sysname'] != "Windows"){
  #mac/linux - uses a fork process that windows does not have
  system.time(mclapply(1:10, chill(2), mc.cores = Ncores))
}else{
  #windows
  cluster <- makePSOCKcluster(Ncores)
  system.time(parLapply(cluster, 1:10, function(i) Sys.sleep(2)))
  stopCluster(cluster)
}
```

However, parallel applications can introduce overhead that can actually slow down the calculations. For example, functions that are already vectorized like finding the square root of all the numbers in a vector.
```{r, echo = TRUE}
#serial
system.time({results <- lapply(1:10000, sqrt)})
#parallel
if(Sys.info()['sysname'] != "Windows"){
  system.time({results <- mclapply(1:10000, sqrt, mc.cores = Ncores)})
}else{
  cluster <- makePSOCKcluster(Ncores)
  system.time(parLapply(cluster, 1:10000, sqrt))
  stopCluster(cluster)
}
```

mclapply is great if your code fits into the apply framework, but sometimes your program is such that you may just want to work with loops. foreach is another parallel R library that comes with base R.
```{r, echo = TRUE}
require("foreach")
```

In order to use foreach you need to register a back end that controls how the loop gets split up amongst the different available cores. For that, you need to either register your cores with doMC (mac/linux) or with doParallel (windows).
```{r, echo = TRUE}
if(Sys.info()['sysname'] != "Windows"){
  require("doMC")
  registerDoMC(Ncores)
}else{
  require("doParallel")
  registerDoParallel("Ncores")
  #snow is also an option
}
```

Using foreach to building linear models from the iris data set with sampling in a for loop.
```{r, echo = TRUE}
#View(iris)
x <- iris[which(iris[,5] != "setosa"), c(1,5)]
trials <- 10000
system.time({
  r <- foreach(icount(trials), .combine=cbind) %dopar% {
    ind <- sample(100, 100, replace = TRUE)
    result1 <- glm(x[ind,2]~x[ind,1],family=binomial(logit))
    coefficients(result1)
  }
})
```

Note the use of %do% instead of %dopar% to run in a serial manner.
```{r, echo = TRUE}
x <- iris[which(iris[,5] != "setosa"), c(1,5)]
trials <- 10000
system.time({
  r <- foreach(icount(trials), .combine=cbind) %do% {
    ind <- sample(100, 100, replace = TRUE)
    result1 <- glm(x[ind,2]~x[ind,1],family=binomial(logit))
    coefficients(result1)
  }
})
```

Be careful about modifying shared vectors, foreach modifies copies of the original vector and therefore does not return what you might expect.
```{r, echo = TRUE}
#serial
x_serial <- c(0,0,0,0,0)
for(i in 1:5){
  x_serial[i] = i*2
}
x_serial
#parallel
x_parallel <- c(0,0,0,0,0)
foreach(i = 1:5) %dopar%{
  x_parallel[i] = i * 2
}
x_parallel
```

For this reason, foreach has a combine function can return the reconstituted vector. The array assignment is moved outside of the foreach loop.
```{r, echo = TRUE}
#parallel foreach with combine
x_cparallel <- c(0,0,0,0,0)
x_cparallel <- foreach(i = 1:5, .combine=c) %dopar%{
  i * 2
}
x_cparallel
```

Prescheduling is another argument that can result in big speed increases ffor parallelized foreach loops. We return to our square root of 10000 integers problem, which was actually faster to run in the serial manner than with using mclapply because the serial execution is vectorized and the parallel implemenation adds some overhead to the calculations.
```{r, echo = TRUE}
#serial
system.time({results <- lapply(1:10000, sqrt)})
#parallel
if(Sys.info()['sysname'] != "Windows"){
  system.time({results <- mclapply(1:10000, sqrt, mc.cores = Ncores)})
}else{
  cluster <- makePSOCKcluster(Ncores)
  system.time(parLapply(cluster, 1:10000, sqrt))
  stopCluster(cluster)
}
```

Adding a prescheduling argument to the foreach loop adds a big reduction in the overhead associated with the parallel calculation. First, using foreach with no prescheduling:
```{r, echo = TRUE}
system.time({
  result <- foreach(x = 1:10000, .options.multicore=list(preschedule=FALSE)) %dopar% {
    sqrt(x)
  }
})
```

But setting prescheduling to TRUE allows for nearly an order of magnitude improvement:
```{r, echo = TRUE}
system.time({
  result <- foreach(x = 1:10000, .options.multicore=list(preschedule=TRUE)) %dopar% {
    sqrt(x)
  }
})
```

However, both of these approaches are much slower than the simple vectorized version of the sqrt function. Prescheduling can still be slower if the variability in the individual jobs is high. For these situations, you might want to look at the use of load balancing and queuing servers. The simplest way to do this is to increase the number of jobs relative to the worker then queue then up so that as a worker finishes a task it gets the next one in line.

Load wine dataset.
```{r, echo = TRUE}
wine <- read.csv("~/git/parallelR/winequality-red.csv", sep=";", header=TRUE)
#View(head(wine))
str(wine)
x <- wine[,1:11]
y <- wine$quality
```

Random forests.
```{r, echo = TRUE}
install.packages("randomForest")
library(randomForest)
Ntrees = 500
system.time({
  randomForest(y=y,x=x,ntree=Ntrees)
})
```

With the foreach package.
```{r, echo = TRUE}
trees_per_core = floor(Ntrees / Ncores)
system.time({
  wine_model <- foreach(trees=rep(trees_per_core, Ncores), .combine=combine, .multicombine=TRUE) %dopar% {
    randomForest(y = y, x = x, ntree = Ntrees)
  }
})
```

# caret (Classification And REgression Training)
```{r, echo = TRUE}
#library("devtools"); install_github("lme4/lme4",dependencies=TRUE) # for caret
library(caret)
library(mlbench)
library(e1071)
data(Sonar)

inTrain <- createDataPartition(y = Sonar$Class, p = .75, list = FALSE)
training <- Sonar[ inTrain,]
testing <- Sonar[-inTrain,]


ctrl <- trainControl(method = "repeatedcv", number = 8, repeats = 8)
grid_rf <- expand.grid(.mtry = c(2, 3, 4))
system.time({
  rf <- train(Class ~ ., data = training,  method = "rf", trControl = ctrl, ntree=750,  tuneGrid = grid_rf)
})
```

We have to reregister with only 1 core to see how this model performs in a serialized manner.
```{r, echo = TRUE}
registerDoMC(1)
system.time({
  rf <- train(Class ~ ., data = training,  method = "rf", trControl = ctrl, ntree=750,  tuneGrid = grid_rf)
})
registerDoMC(Ncores)
```

On Mac run activity monitor and double click on cpu load to get a graphic of core activity.



